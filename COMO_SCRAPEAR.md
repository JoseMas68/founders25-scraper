# ğŸš€ CÃ“MO INICIAR EL SCRAPING - PASO A PASO

## âš¡ INICIO RÃPIDO (3 pasos)

### **PASO 1: Verificar que estÃ¡ funcionando**
```bash
python main_windows.py status
```
**Â¿QuÃ© deberÃ­a ver?** Estado "Active hours" y mÃ©tricas en 0

---

### **PASO 2: Crear archivo con URLs**
```bash
python main_windows.py sample
```
**Â¿QuÃ© hace?** Crea el archivo `data/sample_urls.txt` con URLs de ejemplo

---

### **PASO 3: Scraping masivo**
```bash
python main_windows.py batch data/sample_urls.txt
```
**Â¿QuÃ© hace?** Extrae datos de todas las URLs del archivo

---

## ğŸ¯ SCRAPING INDIVIDUAL

### **Para scrapear una URL especÃ­fica:**
```bash
python main_windows.py single "https://ejemplo.com"
```

### **Ejemplo real:**
```bash
python main_windows.py single "https://quotes.toscrape.com/"
```

---

## ğŸ“ CREAR TUS PROPIAS URLs

### **1. Editar el archivo de URLs:**
```bash
# Edita este archivo:
data/sample_urls.txt
```

### **2. Formato del archivo:**
```
# URLs de ejemplo para batch scraping
# Formato: una URL por lÃ­nea
# Las lÃ­neas que empiecen con # son comentarios

https://www.crunchbase.com/organization/airbnb
https://angel.co/company/airbnb
https://www.producthunt.com/products/airbnb

# Agrega mÃ¡s URLs aquÃ­...
```

### **3. Ejecutar scraping:**
```bash
python main_windows.py batch data/sample_urls.txt
```

---

## ğŸ“Š VER LOS RESULTADOS

### **Archivos generados automÃ¡ticamente:**
- ğŸ“ `data/` - Datos extraÃ­dos (.json)
- ğŸ“ `exports/` - Resultados finales (.json/.csv)
- ğŸ“ `logs/` - Archivos de log

### **Ver Ãºltimo resultado:**
```bash
# Lista los archivos mÃ¡s recientes
ls -la data/
ls -la exports/
```

---

## ğŸ› ï¸ COMANDOS ÃšTILES

### **Ver ayuda completa:**
```bash
python main_windows.py --help
```

### **Ver versiÃ³n:**
```bash
python main_windows.py --version
```

### **Estado actual:**
```bash
python main_windows.py status
```

---

## âš ï¸ NOTAS IMPORTANTES

1. **Usa `main_windows.py`** (NO `main.py`) para evitar problemas de encoding
2. **Horarios**: Funciona solo 8AM-6PM (GMT+1)
3. **Velocidad**: Lento por diseÃ±o (2-4 segundos entre requests)
4. **Sitios protegidos**: Algunos sitios bloquean bots (es normal)
5. **Datos**: Se guardan automÃ¡ticamente

---

## ğŸ‰ Â¡EMPIEZA AHORA!

**Para empezar en 30 segundos:**
1. `python main_windows.py sample`
2. `python main_windows.py batch data/sample_urls.txt`

Â¡Y ya estÃ¡s scrapearando datos!